{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpaAztfiYUl7",
        "outputId": "635e6bfb-afe4-4c23-f4fb-344c4668b22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=44115d50515bd3b9bbeabf98c54e2115cdaf91a49d978a813d678f0ffebaadc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq0o-OjGYPdH"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "from pyspark.ml.stat import Correlation\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RecommenderSystem\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/BDA-Project.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "Kd-07iQ1YWap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df.filter(df['Churn Label'] == 'No')\n",
        "churn_columns = ['Churn Label', 'Churn Category', 'Churn Reason']\n",
        "df_filtered = df_filtered.drop(*churn_columns)\n"
      ],
      "metadata": {
        "id": "phFhGoshYaSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features = df_filtered.select(\n",
        "    'Customer ID', 'Age', 'Gender', 'Senior Citizen', 'Married', 'Dependents', 'Number of Dependents',\n",
        "    'Tenure in Months', 'Phone Service', 'Multiple Lines', 'Internet Service', 'Internet Type',\n",
        "    'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV',\n",
        "    'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Contract'\n",
        ")"
      ],
      "metadata": {
        "id": "NDtJ8OtkYgF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexers = [\n",
        "    StringIndexer(inputCol=column, outputCol=column + \"_index\").fit(user_features)\n",
        "    for column in ['Gender', 'Senior Citizen', 'Married', 'Dependents', 'Phone Service', 'Multiple Lines',\n",
        "                   'Internet Service', 'Internet Type', 'Online Security', 'Online Backup',\n",
        "                   'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies',\n",
        "                   'Streaming Music', 'Unlimited Data', 'Contract']\n",
        "]\n",
        "\n",
        "for indexer in indexers:\n",
        "    user_features = indexer.transform(user_features)\n",
        "\n",
        "encoder = OneHotEncoder(\n",
        "    inputCols=[indexer.getOutputCol() for indexer in indexers],\n",
        "    outputCols=[indexer.getOutputCol() + \"_vec\" for indexer in indexers]\n",
        ")\n",
        "user_features = encoder.fit(user_features).transform(user_features)\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=['Age', 'Number of Dependents', 'Tenure in Months'] +\n",
        "              [indexer.getOutputCol() + \"_vec\" for indexer in indexers],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "user_features = assembler.transform(user_features)\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "scaler_model = scaler.fit(user_features)\n",
        "user_features = scaler_model.transform(user_features)\n"
      ],
      "metadata": {
        "id": "yUqWYBbYYhQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = vec1.dot(vec2)\n",
        "    norm_a = vec1.norm(2)\n",
        "    norm_b = vec2.norm(2)\n",
        "    return dot_product / (norm_a * norm_b)\n",
        "\n",
        "user_features_rdd = user_features.select('Customer ID', 'scaled_features').rdd.map(lambda row: (row['Customer ID'], DenseVector(row['scaled_features'].toArray())))\n",
        "user_features_dict = user_features_rdd.collectAsMap()\n",
        "broadcast_user_features = spark.sparkContext.broadcast(user_features_dict)\n"
      ],
      "metadata": {
        "id": "9N2VFrUHYlIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_users(user_id, broadcast_user_features, top_n=5):\n",
        "    target_vector = broadcast_user_features.value[user_id]\n",
        "    similarities = [(other_user_id, cosine_similarity(target_vector, other_vector))\n",
        "                    for other_user_id, other_vector in broadcast_user_features.value.items()\n",
        "                    if other_user_id != user_id]\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    similar_users = [user_id for user_id, similarity in similarities[:top_n]]\n",
        "    return similar_users\n"
      ],
      "metadata": {
        "id": "43Zz4r2aYs71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_services(user_id, df_filtered, broadcast_user_features, top_n=5):\n",
        "    similar_users_ids = get_similar_users(user_id, broadcast_user_features, top_n)\n",
        "    similar_users_data = df_filtered.filter(df_filtered['Customer ID'].isin(similar_users_ids))\n",
        "\n",
        "    service_columns = ['Internet Type', 'Online Security', 'Online Backup', 'Device Protection Plan',\n",
        "                       'Premium Tech Support', 'Streaming TV', 'Streaming Movies',\n",
        "                       'Streaming Music', 'Unlimited Data', 'Contract']\n",
        "\n",
        "    common_services = similar_users_data.groupBy(service_columns).count().orderBy('count', ascending=False).first()\n",
        "    return common_services.asDict()\n"
      ],
      "metadata": {
        "id": "uHB5rxU6Yx6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_id = '1251-STYSZ'\n",
        "recommended_services = recommend_services(new_user_id, df_filtered, broadcast_user_features)\n",
        "print(recommended_services)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD9i4ryVYy8i",
        "outputId": "8eea3305-1872-4268-b356-bdc8054aecd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Internet Type': 'Fiber Optic', 'Online Security': 'Yes', 'Online Backup': 'No', 'Device Protection Plan': 'No', 'Premium Tech Support': 'No', 'Streaming TV': 'No', 'Streaming Movies': 'No', 'Streaming Music': 'No', 'Unlimited Data': 'Yes', 'Contract': 'One Year', 'count': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_id = '4482-EWFMI'\n",
        "recommended_services = recommend_services(new_user_id, df_filtered, broadcast_user_features)\n",
        "print(recommended_services)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVMWrsdEa8Wy",
        "outputId": "12d680ee-e0a2-4041-9bb8-0e11b6835133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Internet Type': 'Fiber Optic', 'Online Security': 'No', 'Online Backup': 'No', 'Device Protection Plan': 'No', 'Premium Tech Support': 'No', 'Streaming TV': 'No', 'Streaming Movies': 'No', 'Streaming Music': 'No', 'Unlimited Data': 'Yes', 'Contract': 'Month-to-Month', 'count': 5}\n"
          ]
        }
      ]
    }
  ]
}